{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install emot\n",
    "# ! pip install re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import emot, re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, LSTM, Embedding\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig\n",
    "\n",
    "import keras_tuner as kt\n",
    "import keras.backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-16 17:37:14--  http://data/full_dataset/\n",
      "Resolving data (data)... failed: nodename nor servname provided, or not known.\n",
      "wget: unable to resolve host address ‘data’\n",
      "--2022-03-16 17:37:14--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.43.16, 172.217.163.48, 142.251.42.240, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.43.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14174600 (14M) [application/octet-stream]\n",
      "Saving to: ‘goemotions_1.csv.2’\n",
      "\n",
      "goemotions_1.csv.2  100%[===================>]  13.52M  9.79MB/s    in 1.4s    \n",
      "\n",
      "2022-03-16 17:37:17 (9.79 MB/s) - ‘goemotions_1.csv.2’ saved [14174600/14174600]\n",
      "\n",
      "FINISHED --2022-03-16 17:37:17--\n",
      "Total wall clock time: 2.6s\n",
      "Downloaded: 1 files, 14M in 1.4s (9.79 MB/s)\n",
      "--2022-03-16 17:37:17--  http://data/full_dataset/\n",
      "Resolving data (data)... failed: nodename nor servname provided, or not known.\n",
      "wget: unable to resolve host address ‘data’\n",
      "--2022-03-16 17:37:17--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.163.48, 142.251.42.240, 172.217.160.112, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.163.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14173154 (14M) [application/octet-stream]\n",
      "Saving to: ‘goemotions_2.csv.2’\n",
      "\n",
      "goemotions_2.csv.2  100%[===================>]  13.52M  9.24MB/s    in 1.5s    \n",
      "\n",
      "2022-03-16 17:37:19 (9.24 MB/s) - ‘goemotions_2.csv.2’ saved [14173154/14173154]\n",
      "\n",
      "FINISHED --2022-03-16 17:37:19--\n",
      "Total wall clock time: 2.6s\n",
      "Downloaded: 1 files, 14M in 1.5s (9.24 MB/s)\n",
      "--2022-03-16 17:37:20--  http://data/full_dataset/\n",
      "Resolving data (data)... failed: nodename nor servname provided, or not known.\n",
      "wget: unable to resolve host address ‘data’\n",
      "--2022-03-16 17:37:20--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.42.240, 172.217.160.112, 142.251.43.16, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.42.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14395164 (14M) [application/octet-stream]\n",
      "Saving to: ‘goemotions_3.csv.2’\n",
      "\n",
      "goemotions_3.csv.2  100%[===================>]  13.73M  9.19MB/s    in 1.5s    \n",
      "\n",
      "2022-03-16 17:37:22 (9.19 MB/s) - ‘goemotions_3.csv.2’ saved [14395164/14395164]\n",
      "\n",
      "FINISHED --2022-03-16 17:37:22--\n",
      "Total wall clock time: 2.4s\n",
      "Downloaded: 1 files, 14M in 1.5s (9.19 MB/s)\n"
     ]
    }
   ],
   "source": [
    "! wget data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv\n",
    "! wget data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv\n",
    "! wget data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv\n",
    "goemotions_1 = pd.read_csv('goemotions_1.csv')\n",
    "goemotions_2 = pd.read_csv('goemotions_2.csv')\n",
    "goemotions_3 = pd.read_csv('goemotions_3.csv')\n",
    "frames = [goemotions_1, goemotions_2, goemotions_3]\n",
    "df = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211225, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>disgust</th>\n",
       "      <th>embarrassment</th>\n",
       "      <th>excitement</th>\n",
       "      <th>fear</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>grief</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id       author  \\\n",
       "0                                    That game hurt.  eew5j0j        Brdd9   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk  TheGreen888   \n",
       "\n",
       "          subreddit    link_id   parent_id   created_utc  rater_id  \\\n",
       "0               nrl  t3_ajis4z  t1_eew18eq  1.548381e+09         1   \n",
       "1  unpopularopinion  t3_ai4q37   t3_ai4q37  1.548084e+09        37   \n",
       "\n",
       "   example_very_unclear  admiration  amusement  anger  annoyance  approval  \\\n",
       "0                 False           0          0      0          0         0   \n",
       "1                  True           0          0      0          0         0   \n",
       "\n",
       "   caring  confusion  curiosity  desire  disappointment  disapproval  disgust  \\\n",
       "0       0          0          0       0               0            0        0   \n",
       "1       0          0          0       0               0            0        0   \n",
       "\n",
       "   embarrassment  excitement  fear  gratitude  grief  joy  love  nervousness  \\\n",
       "0              0           0     0          0      0    0     0            0   \n",
       "1              0           0     0          0      0    0     0            0   \n",
       "\n",
       "   optimism  pride  realization  relief  remorse  sadness  surprise  neutral  \n",
       "0         0      0            0       0        0        1         0        0  \n",
       "1         0      0            0       0        0        0         0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    207814\n",
       "True       3411\n",
       "Name: example_very_unclear, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.example_very_unclear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire dataset: (211225, 37)\n",
      "207814 rows left after removing records with unclear emotions\n",
      "57730 rows left after deduping on text and id columns\n",
      "53994 rows left after removing records without having at least two raters agreeing on the emotion\n",
      "CPU times: user 4.91 s, sys: 388 ms, total: 5.3 s\n",
      "Wall time: 7.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# emotion label columns\n",
    "lb_col = df.columns[9:]\n",
    "print(f'Entire dataset: {df.shape}')\n",
    "# remove examples that were very unclear. They do not have any emotions labels\n",
    "df2 = df[~df['example_very_unclear']].copy()\n",
    "print(f'{df2.shape[0]} rows left after removing records with unclear emotions')\n",
    "# Sum the emotions together because there are different raters\n",
    "df2 = df2[['text']+list(lb_col)].groupby(['text']).sum().reset_index()\n",
    "print(f'{df2.shape[0]} rows left after deduping on text and id columns')\n",
    "# keep records where there are at least two agreeing emotion labels\n",
    "df2['at_least_2_agree'] = df2[lb_col].apply(lambda x: x.max(), axis=1)\n",
    "df2 = df2[df2.at_least_2_agree >= 2]\n",
    "df2 = df2.replace({1: 0, 2: 1, 3: 1, 4: 1, 5: 1}, inplace=False)\n",
    "df_clean = df2.drop('at_least_2_agree', axis=1)\n",
    "print(f'{df2.shape[0]} rows left after removing records without having at least two raters agreeing on the emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A surprise to be sure, but a welcome one.\n",
    "# a = pd.read_csv(\"train.tsv\",sep='\\t',names=['a','b']).reset_index().rename(columns={'index':'text'})\n",
    "# a[a.text.str.contains('A surprise to be sure, but a welcome one.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53994, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>disgust</th>\n",
       "      <th>embarrassment</th>\n",
       "      <th>excitement</th>\n",
       "      <th>fear</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>grief</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"If you don't wear BROWN AND ORANGE...YOU DON...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"What do Scottish people look like?\" How I wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  admiration  amusement  \\\n",
       "0   \"If you don't wear BROWN AND ORANGE...YOU DON...           0          0   \n",
       "1   \"What do Scottish people look like?\" How I wo...           0          0   \n",
       "\n",
       "   anger  annoyance  approval  caring  confusion  curiosity  desire  \\\n",
       "0      0          1         0       0          0          0       0   \n",
       "1      0          0         0       0          0          1       0   \n",
       "\n",
       "   disappointment  disapproval  disgust  embarrassment  excitement  fear  \\\n",
       "0               0            0        0              0           0     0   \n",
       "1               0            0        0              0           0     0   \n",
       "\n",
       "   gratitude  grief  joy  love  nervousness  optimism  pride  realization  \\\n",
       "0          0      0    0     0            0         0      0            0   \n",
       "1          0      0    0     1            0         0      0            0   \n",
       "\n",
       "   relief  remorse  sadness  surprise  neutral  \n",
       "0       0        0        0         0        1  \n",
       "1       0        0        0         0        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_clean.shape)\n",
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        if emot in text:\n",
    "            orig = text\n",
    "            text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "#             print(f'{orig} -> {text}', '\\n')\n",
    "    return text\n",
    "\n",
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS_EMO:\n",
    "        if emot in text:\n",
    "            orig = text\n",
    "            text = text.replace(emot, \"_\".join(EMOTICONS_EMO[emot].split()))\n",
    "#             print(f'{orig} -> {text}', '\\n')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------replacing emoji with text---------\n",
      "-------replacing emoticon with text---------\n",
      "CPU times: user 7.92 s, sys: 115 ms, total: 8.03 s\n",
      "Wall time: 8.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('-------replacing emoji with text---------')\n",
    "df_clean['text'] = df_clean['text'].apply(lambda x: convert_emojis(x))\n",
    "print('-------replacing emoticon with text---------')\n",
    "df_clean['text'] = df_clean['text'].apply(lambda x: convert_emoticons(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>disgust</th>\n",
       "      <th>embarrassment</th>\n",
       "      <th>excitement</th>\n",
       "      <th>fear</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>grief</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
       "0          0      0          1         0       0          0          0   \n",
       "1          0      0          0         0       0          0          1   \n",
       "\n",
       "   desire  disappointment  disapproval  disgust  embarrassment  excitement  \\\n",
       "0       0               0            0        0              0           0   \n",
       "1       0               0            0        0              0           0   \n",
       "\n",
       "   fear  gratitude  grief  joy  love  nervousness  optimism  pride  \\\n",
       "0     0          0      0    0     0            0         0      0   \n",
       "1     0          0      0    0     1            0         0      0   \n",
       "\n",
       "   realization  relief  remorse  sadness  surprise  neutral  \n",
       "0            0       0        0        0         0        1  \n",
       "1            0       0        0        0         0        0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_clean['text']\n",
    "y = df_clean.iloc[:,2:]\n",
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (43195,)\n",
      "X_val shape: (5399,)\n",
      "X_test shape: (5400,)\n",
      "Y_train shape: (43195, 27)\n",
      "Y_val shape: (5399, 27)\n",
      "Y_test shape: (5400, 27)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.5, random_state=2)\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n",
    "print(f'Y_val shape: {Y_val.shape}')\n",
    "print(f'Y_test shape: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49290 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 3000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 32\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='', lower=True)\n",
    "tokenizer.fit_on_texts(X_train.values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(text, tokenizer):\n",
    "    MAX_SEQUENCE_LENGTH = 32\n",
    "    text = tokenizer.texts_to_sequences(text.values)\n",
    "    text = pad_sequences(text, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "    print('Shape of data tensor:', text.shape)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (43195, 32)\n",
      "Shape of data tensor: (5399, 32)\n",
      "Shape of data tensor: (5400, 32)\n"
     ]
    }
   ],
   "source": [
    "X_train = embedding(X_train, tokenizer)\n",
    "X_val = embedding(X_val, tokenizer)\n",
    "X_test = embedding(X_test, tokenizer)\n",
    "# Y_train = embedding(Y_train)\n",
    "# Y_val = embedding(Y_val)\n",
    "# Y_test = embedding(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_builder(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "#     # Tune the number of units in the first Dense layer\n",
    "#     # Choose an optimal value between 32-512\n",
    "#     hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "#     model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "#     model.add(keras.layers.Dense(10))\n",
    "\n",
    "#     # Tune the learning rate for the optimizer\n",
    "#     # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "#     hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "#     model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "#                 loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        # TODO: build the model, \n",
    "        # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
    "\n",
    "\n",
    "        model=Sequential()\n",
    "        model.add(Embedding(MAX_NB_WORDS,100,input_length=MAX_SEQUENCE_LENGTH))\n",
    "        hp_units_1 = hp.Int('units1', min_value=32, max_value=32, step=32)\n",
    "        model.add(LSTM(hp_units_1,input_shape=(64,),activation='relu',return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "        hp_units_2 = hp.Int('units2', min_value=32, max_value=32, step=32)\n",
    "        model.add(LSTM(hp_units_2,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        # for units in [128,128,64,32]:\n",
    "        # model.add(Dense(units,activation='relu'))\n",
    "        # model.add(Dropout(0.2))\n",
    "        model.add(Dense(32,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(27,activation='sigmoid'))\n",
    "\n",
    "        print(model.summary())\n",
    "\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-4, 1e-5, 1e-6])\n",
    "\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=keras.losses.CategoricalCrossentropy(),\n",
    "                    metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    # def compile_model(model):\n",
    "    #     # TODO: compile the model\n",
    "    #     # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
    "\n",
    "\n",
    "\n",
    "    # #     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #     return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        # TODO: train the model\n",
    "        # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
    "\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [128]),\n",
    "            **kwargs)\n",
    "\n",
    "\n",
    "#     def eval_model(self, model, X_test, Y_test):\n",
    "#         # TODO: evaluate the model\n",
    "#         # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
    "\n",
    "#         test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "#         return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir/intro_to_kt/oracle.json\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 32, 100)           300000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32, 32)            17024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 32)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 27)                891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 327,291\n",
      "Trainable params: 327,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(MyHyperModel(),\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=2,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 36s]\n",
      "val_accuracy: 0.3059825897216797\n",
      "\n",
      "Best val_accuracy So Far: 0.3059825897216797\n",
      "Total elapsed time: 00h 02m 37s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first LSTM\n",
      "layer is 32, the optimal number of units in the second LSTM\n",
      "layer is 32, best batch_size is 128, and the optimal learning rate for the optimizer\n",
      "is 1e-05.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,\n",
    "        Y_train,\n",
    "#         batch_size=128,\n",
    "        epochs=30,\n",
    "        verbose=2,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first LSTM\n",
    "layer is {best_hps.get('units1')}, the optimal number of units in the second LSTM\n",
    "layer is {best_hps.get('units2')}, best batch_size is {best_hps.get('batch_size')}, and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 32, 100)           300000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32, 32)            17024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 32)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 27)                891       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 327,291\n",
      "Trainable params: 327,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "338/338 - 19s - loss: 3.6040 - accuracy: 0.2389 - val_loss: 3.6051 - val_accuracy: 0.3060 - 19s/epoch - 57ms/step\n",
      "Epoch 2/5\n",
      "338/338 - 16s - loss: 3.5898 - accuracy: 0.2743 - val_loss: 3.5838 - val_accuracy: 0.3060 - 16s/epoch - 46ms/step\n",
      "Epoch 3/5\n",
      "338/338 - 16s - loss: 3.5477 - accuracy: 0.2665 - val_loss: 3.4889 - val_accuracy: 0.3060 - 16s/epoch - 48ms/step\n",
      "Epoch 4/5\n",
      "338/338 - 17s - loss: 3.3235 - accuracy: 0.2684 - val_loss: 3.1587 - val_accuracy: 0.3060 - 17s/epoch - 50ms/step\n",
      "Epoch 5/5\n",
      "338/338 - 21s - loss: 3.2127 - accuracy: 0.2883 - val_loss: 3.0975 - val_accuracy: 0.3060 - 21s/epoch - 62ms/step\n",
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train,\n",
    "        Y_train,\n",
    "        batch_size=128,\n",
    "        epochs=5,\n",
    "        verbose=2,\n",
    "        validation_data=(X_val, Y_val))\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
